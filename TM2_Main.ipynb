{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MP2: Text Categorization\n",
    "\n",
    "Hope McIntyre (hm7zg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from os import listdir\n",
    "import math\n",
    "import timeit\n",
    "# Natural Language Processing\n",
    "import nltk\n",
    "from nltk.stem.snowball import EnglishStemmer # load the stemmer module from NLTK\n",
    "# Get an instance of SnowballStemmer for English\n",
    "stemmer = EnglishStemmer() \n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# iPython Notebook\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Stopword List\n",
    "stopwords = open('stopwords.txt', 'r').read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in JSON\n",
    "\n",
    "# Get File Names for Test and Train set\n",
    "files_test = listdir('yelp/test')\n",
    "files_train = listdir('yelp/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_json(fileList,filePath):\n",
    "    dataDF = pd.DataFrame()\n",
    "    for file in fileList:\n",
    "        #json_data = open(filePath+file, encoding = \"ISO-8859-1\").read()\n",
    "        json_data = open(filePath+file, errors = \"ignore\").read()\n",
    "        data = json.loads(json_data)\n",
    "\n",
    "        # Move Reviews only to DataFrame\n",
    "        dataDF = dataDF.append(pd.DataFrame.from_dict(data['Reviews']))\n",
    "        \n",
    "    return dataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of rows:  38688\n"
     ]
    }
   ],
   "source": [
    "dataDF_train = load_json(files_train, 'yelp/train/')\n",
    "\n",
    "text_train = dataDF_train['Content']\n",
    "reviewID_train = dataDF_train['ReviewID']\n",
    "print(\"Num of rows: \",len(text_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_words(text):\n",
    "    tokenizer = nltk.tokenize.treebank.TreebankWordTokenizer()\n",
    "    words = tokenizer.tokenize(text)\n",
    "\n",
    "    # Convert to Lowercase\n",
    "    # words = words.map(str.lower)\n",
    "    cleanWords = [t.lower() for t in words]\n",
    "\n",
    "    # Normalize (remove punctuation)\n",
    "    # punc = string.punctuation\n",
    "    # cleanWords = [t for t in cleanWords if t not in punc]\n",
    "    cleanWords = [re.sub('[^0-9a-z]', \"\", x) for x in cleanWords]\n",
    "    \n",
    "    # Remove Empty Vectors\n",
    "    cleanWords = [x for x in cleanWords if x != '']\n",
    " \n",
    "    # Identify Digits & Convert to Num\n",
    "    cleanWords = [re.sub(\"\\d+\", \"NUM\", x) for x in cleanWords]\n",
    "\n",
    "    # Stem Words\n",
    "    cleanWords = [stemmer.stem(x) for x in cleanWords] # call stemmer to stem the input\n",
    "    \n",
    "    return cleanWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenize & Clean Train Corpus\n",
    "tokens_train = []\n",
    "tokens_train = [clean_words(i) for i in text_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 MLE for statistical language models with proper smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def term_freq(textList):\n",
    "    TF = {}\n",
    "    for row in textList:\n",
    "        #print(row)\n",
    "        for word in row:\n",
    "            # print(word)\n",
    "            if word in TF:\n",
    "                TF[word] += 1\n",
    "            else:\n",
    "                TF[word] = 1\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TTF_train = term_freq(tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>261229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>162202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>144286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>129623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>103806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>95743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>85929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>79493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>60543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>55931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TTF\n",
       "the  261229\n",
       "and  162202\n",
       "i    144286\n",
       "a    129623\n",
       "to   103806\n",
       "was   95743\n",
       "it    85929\n",
       "of    79493\n",
       "is    60543\n",
       "for   55931"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_theta = pd.DataFrame.from_dict(TTF_train, orient = \"index\")\n",
    "u_theta.columns = ['TTF']\n",
    "u_theta.sort('TTF', ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4948882"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Number of Words in Training Corpus\n",
    "nWords_train = u_theta['TTF'].sum()\n",
    "nWords_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64512"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Unique Words in Training Corpus\n",
    "vSize_train = len(u_theta['TTF'])\n",
    "vSize_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTF</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>261229</td>\n",
       "      <td>0.052785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>162202</td>\n",
       "      <td>0.032775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>144286</td>\n",
       "      <td>0.029155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>129623</td>\n",
       "      <td>0.026192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>103806</td>\n",
       "      <td>0.020976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>95743</td>\n",
       "      <td>0.019346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>85929</td>\n",
       "      <td>0.017363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>79493</td>\n",
       "      <td>0.016063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>60543</td>\n",
       "      <td>0.012234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>55931</td>\n",
       "      <td>0.011302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TTF         p\n",
       "the  261229  0.052785\n",
       "and  162202  0.032775\n",
       "i    144286  0.029155\n",
       "a    129623  0.026192\n",
       "to   103806  0.020976\n",
       "was   95743  0.019346\n",
       "it    85929  0.017363\n",
       "of    79493  0.016063\n",
       "is    60543  0.012234\n",
       "for   55931  0.011302"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Probabilty of Each Word by TTF/N\n",
    "u_theta['p'] = u_theta/nWords_train\n",
    "u_theta.sort('TTF', ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999993633"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that Probability Sums to 1\n",
    "u_theta['p'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram with Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Dict of Dict with the Instance of Every nextWord\n",
    "def count_nextWordFreq(textList):\n",
    "    NWF = {}\n",
    "    for tokenList in textList:\n",
    "        for i in range(0,len(tokenList)-1):\n",
    "            word = tokenList[i]\n",
    "            nextWord = tokenList[i+1]\n",
    "            #print(word)\n",
    "            #print(nextWord)\n",
    "            # print(word)\n",
    "            if word in NWF:\n",
    "                if nextWord in NWF[word]:\n",
    "                    NWF[word][nextWord] += 1\n",
    "                else:\n",
    "                    NWF[word][nextWord] = 1\n",
    "            else:\n",
    "                NWF[word] = {}\n",
    "                NWF[word][nextWord] = 1\n",
    "            #print(NWF)\n",
    "    return NWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NWF = count_nextWordFreq(tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lambda Value\n",
    "l = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Smoothed Probability with Linear Interpolation\n",
    "def calc_pSmoothLI(wordi,givenWord, l):\n",
    "    if wordi in NWF[givenWord]:\n",
    "        prob = NWF[givenWord][wordi]/sum(NWF[givenWord].values())\n",
    "    else:\n",
    "        prob = 0\n",
    "    probSmooth = l*prob + (1-l)*u_theta['p'].ix[wordi]\n",
    "    return probSmooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probSmoothLI_good = [calc_pSmoothLI(word, 'good', 0.9) for word in u_theta.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Most Likely Words Following Good: Linear Interpolation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_smooth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>but</th>\n",
       "      <td>0.086325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.062767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.054971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.052512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>0.034262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.027040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>0.018770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>0.017080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.016851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>0.014835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       p_smooth\n",
       "but    0.086325\n",
       "and    0.062767\n",
       "the    0.054971\n",
       "i      0.052512\n",
       "as     0.034262\n",
       "food   0.027040\n",
       "it     0.018770\n",
       "thing  0.017080\n",
       "for    0.016851\n",
       "too    0.014835"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probSmoothLI_good = pd.DataFrame(probSmoothLI_good)\n",
    "probSmoothLI_good.index = u_theta.index\n",
    "probSmoothLI_good.columns = ['p_smooth']\n",
    "print(\"The 10 Most Likely Words Following Good: Linear Interpolation\")\n",
    "probSmoothLI_good.sort('p_smooth',ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000009288"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure the Probabilities add to 1\n",
    "sum(probSmoothLI_good['p_smooth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Absolute Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_pSmoothAD(wordi,givenWord, delta):\n",
    "    #smooth_NWF = {}\n",
    "    givenWordCount = sum(NWF[givenWord].values())\n",
    "    uniqueWords = len(NWF[givenWord])\n",
    "    l = (d*uniqueWords)/(givenWordCount)\n",
    "    #print(givenWordCount)\n",
    "    # calculate lambda value, from w(i-1)\n",
    "    # L = (d*len(u_theta))/sum(u_theta['TTF'])\n",
    "    if wordi in NWF[givenWord]:\n",
    "        #print(NWF[givenWord][wordi])\n",
    "        #print(max(NWF[givenWord][wordi]-delta,0))\n",
    "        probSmooth = (max(NWF[givenWord][wordi]-delta,0)/givenWordCount) + l*u_theta['p'].ix[wordi]\n",
    "        #print(probSmooth)\n",
    "    else: \n",
    "        probSmooth = l*u_theta['p'].ix[wordi]\n",
    "        #print(probSmooth)\n",
    "    return probSmooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delta - Given\n",
    "d = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probSmoothAD_good = [calc_pSmoothAD(word, 'good', d) for word in u_theta.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 Most Likely Words Following Good: Absolute Discount Smooth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_smooth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>but</th>\n",
       "      <td>0.094913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.066339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.055601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.055319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>0.037631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.029526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>0.019051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>0.018827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.017548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>0.016270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       p_smooth\n",
       "but    0.094913\n",
       "and    0.066339\n",
       "the    0.055601\n",
       "i      0.055319\n",
       "as     0.037631\n",
       "food   0.029526\n",
       "it     0.019051\n",
       "thing  0.018827\n",
       "for    0.017548\n",
       "too    0.016270"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probSmoothAD_good = pd.DataFrame(probSmoothAD_good)\n",
    "probSmoothAD_good.index = u_theta.index\n",
    "probSmoothAD_good.columns = ['p_smooth']\n",
    "print(\"The 10 Most Likely Words Following Good: Absolute Discount Smooth\")\n",
    "probSmoothAD_good.sort('p_smooth',ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999999883449"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure the Probabilities add to 1\n",
    "sum(probSmoothAD_good['p_smooth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Are those top 10 words the same from these two bigram language models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: Yes, the words are the same from the two bigram language models, though the probability of each word does vary slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Generate text documents from a language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate 15 Word Sentence from Unigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Sentences - Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram Model Generated Sentences:\n",
      "\n",
      "1 ['mass', 'were', 'bit', 'had', 'a', 'when', 'came', 'dog', 'restaur', 'man', 'health', 'on', 'tri', 'need', 'grew']\n",
      "Probability of Generated Sentence =  9.64946525588e-47\n",
      "2 ['the', 's', 'long', 'food', 'been', 'so', 'toward', 'the', 'the', 'and', 'quick', 'for', 'pretti', 'and', 'stuf']\n",
      "Probability of Generated Sentence =  5.66744040088e-36\n",
      "3 ['fri', 'outsid', 'billeh', 'old', 'corn', 'up', 'around', 'hostess', 's', 'marin', 'tender', 'like', 'with', 'small', 'fuzzi']\n",
      "Probability of Generated Sentence =  3.05381355006e-52\n",
      "4 ['tri', 'flavor', 'my', 'drink', 'everi', 'super', 'and', 'michigan', 'the', 'love', 'love', 'in', 's', 'she', 'this']\n",
      "Probability of Generated Sentence =  3.07117627767e-39\n",
      "5 ['end', 'best', 'are', 'europ', 'rare', 'a', 'northsid', 'time', 'realli', 'from', 'roster', 'time', 'admit', 'for', 'there']\n",
      "Probability of Generated Sentence =  1.24002414962e-49\n",
      "6 ['di', 'the', 'tast', 'spain', 'lamb', 'the', 'when', 'ononc', 'get', 'just', 'pizza', 'can', 'but', 'never', 'tude']\n",
      "Probability of Generated Sentence =  5.24808813422e-49\n",
      "7 ['for', 'back', 'is', 'bacon', 'there', 'reduct', 'and', 'and', 'i', 'space', 'wait', 're', 'trip', 'get', 'the']\n",
      "Probability of Generated Sentence =  5.01507168557e-39\n",
      "8 ['brunch', 'all', 'third', 'either', 'bellota', 's', 'had', 'insid', 'just', 'star', 'burn', 'sure', 'super', 'be', 'heavi']\n",
      "Probability of Generated Sentence =  2.64627791391e-50\n",
      "9 ['is', '2', 'astonish', 'then', 'the', 'cure', 'seem', 'if', 'whether', 'good', 'all', 'on', 'was', 'can', 'there']\n",
      "Probability of Generated Sentence =  2.45723073817e-43\n",
      "10 ['with', 'your', 'one', 'pricey', 'banana', 'to', 'realli', 'both', 'drool', 'got', 'i', 'our', 'trip', 'so', 'have']\n",
      "Probability of Generated Sentence =  2.96379573859e-42\n"
     ]
    }
   ],
   "source": [
    "# Randomly Sample 15 word sentences from the Probability Distribution of the Unigram Language Model\n",
    "print(\"Unigram Model Generated Sentences:\\n\")\n",
    "genSentences_u = []\n",
    "genSentencesProb_u = []\n",
    "for i in range(0,10): # Number of Sentences\n",
    "    genSent_u = []\n",
    "    genSent_prob = 1\n",
    "    for j in range(0,15): # Number of Words in Sentences\n",
    "        # Randomly Sample Word from Unigram Distribution\n",
    "        # np.random.choice randomly samples from a set of values given a vector of probabilities (p)\n",
    "        selectedWord = np.random.choice(u_theta.index, size = 1, p = u_theta['p'])[0]\n",
    "        genSent_u.append(selectedWord)\n",
    "        # Fetch Probability of Selected Word\n",
    "        prob_selectedWord = u_theta['p'].ix[selectedWord]\n",
    "        genSent_prob = genSent_prob*prob_selectedWord\n",
    "    print(i+1, genSent_u)\n",
    "    print('Probability of Generated Sentence = ',genSent_prob)\n",
    "    # Store Just in Case\n",
    "    genSentences_u.append(genSent_u)\n",
    "    genSentencesProb_u.append(genSent_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Sentences - Bigram Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram L.I. Model Generated Sentences:\n",
      "\n",
      "1 ['not', 'on', 'this', 'i', 'crisp', 'to', 'welcom', 'a', 'runni', 'for', 'visit', 'all', 'of', 'chai', 'tast']\n",
      "Probability of Generated Sentence =  5.88608659982e-41\n",
      "2 ['bar', 'and', 'that', 'even', 'in', 'the', 'for', 'gotten', 'oh', 'that', 'price', 'at', 'a', 'nice', 'staff']\n",
      "Probability of Generated Sentence =  3.29121339835e-35\n",
      "3 ['servic', 'was', 'expect', 'to', 'the', 'menu', 'were', 'good', 'but', 'it', 'from', 'what', 'to', 'maxim', 'the']\n",
      "Probability of Generated Sentence =  1.44576715016e-27\n",
      "4 ['m', 'there', 'is', 'one', 'friend', 'and', 'wait', 'and', 'cycl', 'but', 'i', 've', 'ever', 'in', 'the']\n",
      "Probability of Generated Sentence =  3.40935628966e-29\n",
      "5 ['person', 'pizza', 'and', 'possibl', 'the', 'rich', 'flavor', 'and', 'the', 'chicken', 'and', 'ham', 'saute', 'whole', 'tabl']\n",
      "Probability of Generated Sentence =  4.19077500239e-34\n",
      "6 ['crowd', 'dure', 'blackhawk', 'won', 'a', 'hot', 'order', 'asap', 'love', 'fri', 'are', 'appropri', 'bring', 'their', 'sure']\n",
      "Probability of Generated Sentence =  1.05265301245e-41\n",
      "7 ['chili', 'was', 'a', 'trio', 'of', 'farci', 'the', 'weekend', 'of', 'spice', 'just', 'my', 'tabl', 'was', 'a']\n",
      "Probability of Generated Sentence =  3.62898776055e-34\n",
      "8 ['will', 'most', 'like', 'brie', 'toast', 'from', 'me', 'haha', 'did', 'i', 'check', 'to', 'the', 'butteri', 'honey']\n",
      "Probability of Generated Sentence =  1.08859093212e-42\n",
      "9 ['to', 'my', 'entre', 'as', 'well', 'menu', 'with', 'a', 'pretti', 'tasti', 'i', 've', 'seen', 'me', 'through']\n",
      "Probability of Generated Sentence =  3.04912019632e-30\n",
      "10 ['pineappl', 'the', 'wooden', 'insid', 'it', 'again', 'it', 'then', 'ate', 'was', 'overcook', 'them', 'and', 'fought', 'their']\n",
      "Probability of Generated Sentence =  3.28541006959e-39\n"
     ]
    }
   ],
   "source": [
    "# Randomly Sample 15 word sentences from the Probability Distribution of the Bigram Linear Interpolation Model\n",
    "# NEED TO ADD SMOOTHING, BUT WHERE?\n",
    "print(\"Bigram L.I. Model Generated Sentences:\\n\")\n",
    "\n",
    "genSentences_biLI = []\n",
    "genSentencesProb_biLI = []\n",
    "for i in range(0,10): # Number of Sentences\n",
    "    genSent = []\n",
    "    for j in range(0,15): # Number of Words in Sentences\n",
    "        if j == 0:\n",
    "            # Randomly Sample Word from Unigram Distribution\n",
    "            # np.random.choice randomly samples from a set of values given a vector of probabilities (p)\n",
    "            selectedWord = np.random.choice(u_theta.index, size = 1, p = u_theta['p'])[0]\n",
    "            genSent.append(selectedWord)\n",
    "            genSent_prob = u_theta['p'].ix[selectedWord]\n",
    "        else:\n",
    "            prob = [calc_pSmoothLI(word, genSent[j-1], 0.9) for word in u_theta.index]\n",
    "            prob = pd.DataFrame(prob)\n",
    "            prob.index = u_theta.index\n",
    "            prob.columns = ['p_smooth']\n",
    "            selectedWord = np.random.choice(prob.index, size = 1, p = prob['p_smooth'])[0]\n",
    "            genSent.append(selectedWord)\n",
    "            genSent_prob = genSent_prob*prob['p_smooth'].ix[selectedWord]\n",
    "    print(i+1, genSent)\n",
    "    print('Probability of Generated Sentence = ',genSent_prob)\n",
    "    # Store Just in Case\n",
    "    genSentences_biLI.append(genSent)\n",
    "    genSentencesProb_biLI.append(genSent_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Sentences - Bigram Absolute Discount Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigram A.D. Model Generated Sentences:\n",
      "\n",
      "1 ['went', 'here', 'has', 'grill', 'chees', 'was', 'feel', 'special', 'was', 'much', 'much', 'enjoy', 'thati', 'think', 'i']\n",
      "Probability of Generated Sentence =  3.76118445877e-34\n",
      "2 ['their', 'food', 'came', 'back', 'in', 'their', 'sauc', 'and', 'cash', 'regist', 'the', 'date', 'were', 'wonder', 'i']\n",
      "Probability of Generated Sentence =  2.36565416869e-29\n",
      "3 ['the', 'server', 'preemptiv', 'brought', 'it', 'was', 'pretti', 'good', 'these', 'textur', 'to', 'get', 'my', '13', 'day']\n",
      "Probability of Generated Sentence =  2.49112136875e-32\n",
      "4 ['of', 'sushi', 'rice', 'these', 'kind', 'and', 'matin', 'martini', 'glass', 'of', 'the', 'price', 'the', 'wait', 'for']\n",
      "Probability of Generated Sentence =  2.78654883325e-28\n",
      "5 ['thought', 'about', 'this', 'place', 'for', 'the', 'waitress', 'split', 'an', 'avid', 'riesl', 'i', 'opt', 'to', 'wait']\n",
      "Probability of Generated Sentence =  3.98046725781e-27\n",
      "6 ['which', 'was', 'occupi', 'the', 'wine', 'select', 'and', 'one', 'and', 'i', 'do', 'nt', 'realli', 'want', 'to']\n",
      "Probability of Generated Sentence =  7.15441680023e-25\n",
      "7 ['and', 'enjoy', 'meal', 'with', 'a', 'crowd', 'when', 'it', 'is', 'finemi', 'friend', 'we', 'came', 'the', 'meal']\n",
      "Probability of Generated Sentence =  6.01920007295e-30\n",
      "8 ['this', 'was', 'cancel', 'our', 'second', 'the', 'drink', 'sangria', 'and', 'you', 'may', 'not', 'eat', 'insid', 'did']\n",
      "Probability of Generated Sentence =  1.55068802939e-32\n",
      "9 ['with', 'red', 'cabbag', 'in', 'town', 'dure', 'a', 'beach', 'that', 'have', 'the', 'sushi', 'when', 'she', 'order']\n",
      "Probability of Generated Sentence =  4.73045325802e-35\n",
      "10 ['pizza', 'place', 'get', 'definit', 'be', 'over', 'and', 'you', 'go', 'again', 'a', 'snack', 'befor', 'the', 'restaur']\n",
      "Probability of Generated Sentence =  5.39784552187e-31\n"
     ]
    }
   ],
   "source": [
    "print(\"Bigram A.D. Model Generated Sentences:\\n\")\n",
    "\n",
    "genSentences_biAD = []\n",
    "genSentencesProb_biAD = []\n",
    "\n",
    "for i in range(0,10): # Number of Sentences\n",
    "    genSent = []\n",
    "    for j in range(0,15): # Number of Words in Sentences\n",
    "        if j == 0:\n",
    "            # Randomly Sample Word from Unigram Distribution\n",
    "            # np.random.choice randomly samples from a set of values given a vector of probabilities (p)\n",
    "            selectedWord = np.random.choice(u_theta.index, size = 1, p = u_theta['p'])[0]\n",
    "            genSent.append(selectedWord)\n",
    "            genSent_prob = u_theta['p'].ix[selectedWord]\n",
    "        else:\n",
    "            prob = [calc_pSmoothAD(word, genSent[j-1], d) for word in u_theta.index]\n",
    "            prob = pd.DataFrame(prob)\n",
    "            prob.index = u_theta.index\n",
    "            prob.columns = ['p_smooth']\n",
    "            selectedWord = np.random.choice(prob.index, size = 1, p = prob['p_smooth'])[0]\n",
    "            genSent.append(selectedWord)\n",
    "            genSent_prob = genSent_prob*prob['p_smooth'].ix[selectedWord]\n",
    "    print(i+1, genSent)\n",
    "    print('Probability of Generated Sentence = ',genSent_prob)\n",
    "    # Store Just in Case\n",
    "    genSentences_biLI.append(genSent)\n",
    "    genSentencesProb_biLI.append(genSent_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Language model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of rows:  19803\n"
     ]
    }
   ],
   "source": [
    "dataDF_test = load_json(files_test, 'yelp/test/')\n",
    "\n",
    "# Extract Only Text Values in PD Series\n",
    "text_test = dataDF_test['Content']\n",
    "reviewID_test = dataDF_test['ReviewID']\n",
    "print(\"Num of rows: \",len(text_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenize & Clean Train Corpus\n",
    "tokens_test = []\n",
    "tokens_test = [clean_words(i) for i in text_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram Model Perplexity Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_perplexity(tokenList):\n",
    "    if tokenList != []:\n",
    "        doc_length = len(tokenList)\n",
    "        pSmooth = calc_pSmoothAdditive(tokenList, 0.1, vSize_train, nWords_train)\n",
    "        #print(doc_length)\n",
    "        perp = 1\n",
    "        for word in tokenList:\n",
    "            probs = pSmooth.ix[word]\n",
    "            # Modified Perplexity Calculation to Mathematical Equivalent - Raising the Inverse Liklihood \n",
    "            # of Each Probability to the Sqrt of N then Multiplying Values for Each Word Together\n",
    "            perp = perp*((1/probs)**(1/doc_length))\n",
    "        return perp\n",
    "    else:\n",
    "        return np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_pSmoothAdditive(tokenList, d, vSize_train, nWords_train):\n",
    "    unseenWords = list(set(tokenList) - set(u_theta.index))\n",
    "    #print(len(unseenWords))\n",
    "    if len(unseenWords) == 0:\n",
    "        return u_theta['p']\n",
    "    else:\n",
    "        # Build Series with all unique words in training set + unseen words from test document\n",
    "        pSmooth = u_theta['TTF'].append(pd.Series(([0]*len(unseenWords)), index = unseenWords))\n",
    "        nWords_train += len(unseenWords)\n",
    "        vSize_train += len(unseenWords)\n",
    "        f = lambda x: ((x + d) / (nWords_train + d*vSize_train))\n",
    "        pSmooth = pSmooth.map(f)\n",
    "        return pSmooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perp_test = []\n",
    "perp_test = [calc_perplexity(i) for i in tokens_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Document By Document Perplexity to Data DataFrame\n",
    "dataDF_test['perp_u'] = perp_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataDF_test.sort('perp_u', ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759.6233519870582"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Perplexity\n",
    "mean_perp_u = dataDF_test['perp_u'].mean()\n",
    "mean_perp_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55800.82900697847"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Std. Deviation Perplextiy\n",
    "stddev_perp_u = np.std(dataDF_test['perp_u'])\n",
    "stddev_perp_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Model - L.I. Perplexity Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_perplexityLI(tokenList):\n",
    "    if tokenList != []:\n",
    "        pSmooth_uni = calc_pSmoothAdditive(tokenList, d, vSize_train, nWords_train)\n",
    "\n",
    "        doc_length = len(tokenList)\n",
    "        \n",
    "        perp = 1\n",
    "        \n",
    "        for i in range(1,len(tokenList)):\n",
    "            # This needs to use the smoothed with unseen words dist\n",
    "            # print(tokenList[i],tokenList[i-1])\n",
    "            probs = calc_pSmoothLI_perpMod(tokenList[i], tokenList[i-1], 0.9, pSmooth_uni)\n",
    "            # Modified Perplexity Calculation to Mathematical Equivalent - Raising the Inverse Liklihood \n",
    "            # of Each Probability to the Sqrt of N then Multiplying Values for Each Word Together\n",
    "            perp = perp*((1/probs)**(1/doc_length))\n",
    "        return perp\n",
    "    else:\n",
    "        return np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_pSmoothLI_perpMod(wordi,givenWord, l, uni_probDist):\n",
    "    if givenWord in NWF.keys():\n",
    "        if wordi in NWF[givenWord]:\n",
    "            prob = NWF[givenWord][wordi]/sum(NWF[givenWord].values())\n",
    "        else:\n",
    "            prob = 0\n",
    "    else: # Case where givenWord is unseen in Training\n",
    "        prob = 1/vSize_train\n",
    "    probSmooth = l*prob + (1-l)*uni_probDist.ix[wordi]\n",
    "    return probSmooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perpLI_test = []\n",
    "perpLI_test = [calc_perplexityLI(i) for i in tokens_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Document By Document Perplexity to Data DataFrame\n",
    "dataDF_test['perp_biLI'] = perpLI_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataDF_test.sort('perp_biLI', ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249.80536916631573"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Perplexity\n",
    "mean_perp_biLI = dataDF_test['perp_biLI'].mean()\n",
    "mean_perp_biLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2032.001430748753"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Std. Deviation Perplextiy\n",
    "stddev_perp_biLI = np.std(dataDF_test['perp_biLI'])\n",
    "stddev_perp_biLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Model - A.D. Perplexity Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_perplexityAD(tokenList):\n",
    "    if tokenList != []:\n",
    "        pSmooth_uni = calc_pSmoothAdditive(tokenList, d, vSize_train, nWords_train)\n",
    "        doc_length = len(tokenList)\n",
    "        \n",
    "        perp = 1\n",
    "        for i in range(1,len(tokenList)):\n",
    "            probs = calc_pSmoothAD_perpMod(tokenList[i], tokenList[i-1], 0.1, pSmooth_uni)\n",
    "            # Modified Perplexity Calculation to Mathematical Equivalent - Raising the Inverse Liklihood \n",
    "            # of Each Probability to the Sqrt of N then Multiplying Values for Each Word Together\n",
    "            perp = perp*((1/probs)**(1/doc_length))\n",
    "        return perp\n",
    "    else:\n",
    "        return np.NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_pSmoothAD_perpMod(wordi,givenWord, delta, uni_probDist):\n",
    "    if givenWord in NWF.keys():\n",
    "        givenWordCount = sum(NWF[givenWord].values())\n",
    "        uniqueWords = len(NWF[givenWord])\n",
    "        l = (d*uniqueWords)/(givenWordCount)\n",
    "        if wordi in NWF[givenWord]:\n",
    "            probSmooth = (max(NWF[givenWord][wordi]-delta,0)/givenWordCount) + l*uni_probDist.ix[wordi]\n",
    "        else: \n",
    "            probSmooth = l*uni_probDist.ix[wordi]\n",
    "    else: # Case where givenWord is unseen in Training\n",
    "        probSmooth = 1/vSize_train\n",
    "    return probSmooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perpAD_test = []\n",
    "perpAD_test = [calc_perplexityAD(i) for i in tokens_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Document By Document Perplexity to Data DataFrame\n",
    "dataDF_test['perp_biAD'] = perpAD_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataDF_test.sort('perp_biAD', ascending = False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379.10818626482325"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Perplexity\n",
    "mean_perp_biAD = dataDF_test['perp_biAD'].mean()\n",
    "mean_perp_biAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6665.424039280692"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Std. Deviation Perplextiy\n",
    "stddev_perp_biAD = np.std(dataDF_test['perp_biAD'])\n",
    "stddev_perp_biAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Can you conclude which language model predicts the data in test folder better? And why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: The bigram Linear Interpolation model predicts the data in the test folder the best. I can tell this because the mean and standard deviation of the perplexity calculated on the Test Set is the lowest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
